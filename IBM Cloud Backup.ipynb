{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 30, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "execution_count": 31, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "ename": "FileExistsError", 
                    "evalue": "[Errno 17] File exists: './ibmcloud-backups-2019-08-14-15-42'", 
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", 
                        "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-31-c78d21c1035e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mbase_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./ibmcloud-backups-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y-%m-%d-%H-%M\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m# TODO: Save as asset files/folders instead of to PC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: './ibmcloud-backups-2019-08-14-15-42'"
                    ], 
                    "output_type": "error"
                }
            ], 
            "source": "import json\nimport ibm_watson\nimport os\nimport shutil\nimport threading\nimport time\nimport datetime\nimport ibm_boto3\nfrom ibm_botocore.client import Config, ClientError\nfrom datetime import date\nfrom pymongo import MongoClient\nfrom ibm_watson import ApiException\n\nbase_directory = './ibmcloud-backups-' + datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\nos.mkdir(base_directory)\n# TODO: Save as asset files/folders instead of to PC"
        }, 
        {
            "source": "Credentials", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 32, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "wa_version = {'wa-version'}\nwa_apikey = {'wa-apikey'}\nwa_url = {'wa-url'}\ndisc_version={'disc-version'}\ndisc_apikey={'disc-apikey'}\ndisc_url={'disc-url'}\ncos_apikey = {'cos-apikey'}\ncos_endpoint = {'cos-endpoint'}\ncos_auth_endpoint = {'cos-auth-endpoint'}\ncos_resource_crn = {'cos-resource-crn'}"
        }, 
        {
            "execution_count": 34, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "############################################\n# This section provides functions needed to\n# get all document IDs from a given\n# Discovery collection\n############################################\ndef pmap_helper(fn, output_list, input_list, i):\n    output_list[i] = fn(input_list[i])\n\ndef pmap(fn, input):\n    input_list = list(input)\n    output_list = [None for _ in range(len(input_list))]\n    threads = [threading.Thread(target=pmap_helper,\n                                args=(fn, output_list, input_list, i),\n                                daemon=True)\n               for i in range(len(input_list))]\n    for t in threads:\n        t.start()\n    for t in threads:\n        t.join()\n    return output_list\n\ndef all_document_ids(discovery,\n                     environmentId,\n                     collectionId):\n    doc_ids = []\n    alphabet = \"0123456789abcdef\"\n    chunk_size = 10000\n\n    def maybe_some_ids(prefix):\n        need_results = True\n        while need_results:\n            try:\n                response = discovery.query(environmentId,\n                                           collectionId,\n                                           count=chunk_size,\n                                           filter=\"extracted_metadata.sha1::\"\n                                           + prefix + \"*\",\n                                           return_fields=\"extracted_metadata.sha1\").get_result()\n                need_results = False\n            except Exception as e:\n                print(\"will retry after error\", e)\n\n        if response[\"matching_results\"] > chunk_size:\n            return prefix\n        else:\n            return [item[\"id\"] for item in response[\"results\"]]\n\n    prefixes_to_process = [\"\"]\n    while prefixes_to_process:\n        prefix = prefixes_to_process.pop(0)\n        prefixes = [prefix + letter for letter in alphabet]\n        # `pmap` here does the requests to Discovery concurrently to save time.\n        results = pmap(maybe_some_ids, prefixes)\n        for result in results:\n            if isinstance(result, list):\n                doc_ids += result\n            else:\n                prefixes_to_process.append(result)\n\n    return doc_ids\n############################################"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "############################################\n# Watson Assistant backup\n############################################\nif(wa_version == '' or wa_apikey == '' or wa_url == ''):\n    print(\"No or invalid Watson Assistant credentials detected. Skipping.\")\nelse:\n    print(\"Starting Watson Assistant backup...\")\n    start_time = time.time()\n\n    assistant_service=ibm_watson.AssistantV1(\n        version = wa_version,\n        iam_apikey = wa_apikey,\n        url = wa_url\n    )\n\n    # Get all workspace IDs\n    try:\n        list_wrkspc_response = assistant_service.list_workspaces().get_result()['workspaces']\n        all_wrkspc_ids = []\n    except ApiException as ex:\n        print(\"Method failed with status code \" + str(ex.code) + \": \" + ex.message)\n\n    print(\"Getting workspace IDs...\")\n    for space in list_wrkspc_response:\n        print(\"Backing up Workspace \"+ space['workspace_id'] + \"...\")\n        all_wrkspc_ids.append(space['workspace_id'])\n\n    for id in all_wrkspc_ids:\n        assistant_path = base_directory + \"/assistant_\"+ id\n        if os.path.exists(assistant_path):\n            shutil.rmtree(assistant_path)\n        os.mkdir(assistant_path)\n\n        workspace_response = []\n        intents_response = []\n        entities_response = []\n\n        try:\n            workspace_response = assistant_service.get_workspace(\n                workspace_id = id,\n                export='true'\n            ).get_result()\n\n            intents_response = assistant_service.list_intents(\n                workspace_id = id\n            ).get_result()\n\n            entities_response = assistant_service.list_entities(\n                workspace_id = id\n            ).get_result()\n        except ApiException as ex:\n            print(\"Method failed with status code \" + str(ex.code) + \": \" + ex.message)\n\n        try:\n            completePath = os.path.join(assistant_path, \"workspace_\" + id + \".json\")\n            workspace_file = open(completePath, \"w\")\n            workspace_file.write(json.dumps(workspace_response))\n            workspace_file.close()\n\n            completePath = os.path.join(assistant_path, \"intents_\" + id + \".json\")\n            intents_file = open(completePath, \"w\")\n            intents_file.write(json.dumps(intents_response))\n            intents_file.close()\n\n            completePath = os.path.join(assistant_path, \"entities_\" + id + \".json\")\n            entities_file = open(completePath, \"w\")\n            entities_file.write(json.dumps(entities_response))\n            entities_file.close()\n\n            print(\"Workspace \" + id + \" done.\")\n        except Exception as e:\n            print(\"Exception occured: \" + e.message)\n\n    end_time = time.time()\n    elapsed = end_time - start_time\n    print(\"Completed Watson Assistant backup in \" + str(elapsed) + \" seconds.\")\n######## End Watson Assistant Backup ########"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "############################################\n# Discovery Backup\n############################################\n# This script will loop through every collection in the given instance and save each document. If you only want a specific collection to be backed up, remove the outer loop.\n\nif(disc_version == '' or disc_apikey == '' or disc_url == ''):\n    print(\"No or invalid Discovery credentials detected. Skipping.\")\nelse:\n    print(\"Beginning Discovery backup...\")\n    start_time = time.time()\n\n    discovery_service = ibm_watson.DiscoveryV1(\n        version=disc_version,\n        iam_apikey=disc_apikey,\n        url=disc_url\n    )\n\n    environments = discovery_service.list_environments().get_result()\n    environmentId = environments[\"environments\"][1][\"environment_id\"]\n    allCollections = discovery_service.list_collections(environmentId).get_result()['collections']\n\n    for collection in allCollections:\n        collectionId = collection['collection_id']\n        print(\"Backing up collection \" + collectionId + \"...\")\n        allDocIds = all_document_ids(discovery_service, environmentId, collectionId)\n\n        discovery_path = base_directory + \"/discovery_\" + collectionId\n        if os.path.exists(discovery_path):\n            shutil.rmtree(discovery_path)\n        os.mkdir(discovery_path)\n\n        try:\n            training_data = discovery_service.list_training_data(environmentId, collectionId).get_result()\n        except ApiException as ex:\n            print(\"Discovery query failed with status code \" + str(ex.code) + \": \" + ex.message)\n        try:\n            completePath = os.path.join(discovery_path, \"_trainingdata.json\")\n            discovery_file = open(completePath, \"w\")\n            discovery_file.write(json.dumps(training_data))\n            discovery_file.close()\n            print(\"Training data for \" + collectionId + \" successfully saved.\")\n        except Exception as e:\n            print(\"Exception occured: \" + e.message)\n\n        for documentId in allDocIds:\n            filterId = '_id:' + documentId\n            try:\n                discQuery = discovery_service.query(environmentId, collectionId, filter=filterId).get_result()['results'][0]\n            except ApiException as ex:\n                print(\"Discovery query failed with status code \" + str(ex.code) + \": \" + ex.message)\n            try:\n                completePath = os.path.join(discovery_path, \"document\" + documentId + \".json\")\n                discovery_file = open(completePath, \"w\")\n                discovery_file.write(json.dumps(discQuery))\n                discovery_file.close()\n            except Exception as e:\n                print(\"Exception occured: \" + e.message)\n\n        print(\"Collection \" + collectionId + \" successfully backed up.\")\n\n    end_time = time.time()\n    elapsed = end_time - start_time\n    print(\"Completed Discovery backup in \" + str(elapsed) + \" seconds.\")\n\n######## End Discovery Backup ########"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "############################################\n# Cloud Object Storage\n############################################\nif(cos_apikey == '' or cos_resource_crn == '' or cos_auth_endpoint == '' or cos_endpoint == ''):\n    print(\"No or invalid COS credentials detected. Skipping.\")\nelse:\n    cos = ibm_boto3.resource(\"s3\",\n        ibm_api_key_id=cos_apikey,\n        ibm_service_instance_id=cos_resource_crn,\n        ibm_auth_endpoint=cos_auth_endpoint,\n        config=Config(signature_version=\"oauth\"),\n        endpoint_url=cos_endpoint\n    )\n\n    try:\n        buckets = cos.buckets.all()\n    except Exception as e:\n        print(\"Unable to retrieve buckets: {0}\".format(e))\n\n    for bucket in buckets:\n        print(\"Backing up Bucket {0}...\".format(bucket.name))\n        cos_path = base_directory + \"/cos_\" + bucket.name\n        if os.path.exists(cos_path):\n            shutil.rmtree(cos_path)\n        os.mkdir(cos_path)\n        try:\n            files = cos.Bucket(bucket.name).objects.all()\n        except Exeception as e:\n            print(\"Unable to get objects in bucket: {0}\".format(e))\n        for file in files:\n            try:\n                fileName = file.key.replace(\"/\", \"-\")\n                completePath = os.path.join(cos_path, fileName)\n                downloadedFile = cos.meta.client.download_file(bucket.name,  file.key, completePath)\n            except Exception as e:\n                print(\"Exception occured: \")\n                print(e)\n        print(\"Bucket {0} backup complete.\".format(bucket.name))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}