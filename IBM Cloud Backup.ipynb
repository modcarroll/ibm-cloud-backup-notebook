{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import json\nimport ibm_watson\nimport threading"
        }, 
        {
            "source": "Credentials", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "wa_version = {'wa-version'}\nwa_apikey = {'wa-apikey'}\nwa_url = {'wa-url'}\ndisc_version={'disc-version'}\ndisc_apikey={'disc-apikey'}\ndisc_url={'disc-url'}"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "############################################\n# This section provides functions needed to\n# get all document IDs from a given\n# Discovery collection\n############################################\ndef pmap_helper(fn, output_list, input_list, i):\n    output_list[i] = fn(input_list[i])\n\ndef pmap(fn, input):\n    input_list = list(input)\n    output_list = [None for _ in range(len(input_list))]\n    threads = [threading.Thread(target=pmap_helper,\n                                args=(fn, output_list, input_list, i),\n                                daemon=True)\n               for i in range(len(input_list))]\n    for t in threads:\n        t.start()\n    for t in threads:\n        t.join()\n    return output_list\n\ndef all_document_ids(discovery,\n                     environmentId,\n                     collectionId):\n    doc_ids = []\n    alphabet = \"0123456789abcdef\"\n    chunk_size = 10000\n\n    def maybe_some_ids(prefix):\n        need_results = True\n        while need_results:\n            try:\n                response = discovery.query(environmentId,\n                                           collectionId,\n                                           count=chunk_size,\n                                           filter=\"extracted_metadata.sha1::\"\n                                           + prefix + \"*\",\n                                           return_fields=\"extracted_metadata.sha1\").get_result()\n                need_results = False\n            except Exception as e:\n                print(\"will retry after error\", e)\n\n        if response[\"matching_results\"] > chunk_size:\n            return prefix\n        else:\n            return [item[\"id\"] for item in response[\"results\"]]\n\n    prefixes_to_process = [\"\"]\n    while prefixes_to_process:\n        prefix = prefixes_to_process.pop(0)\n        prefixes = [prefix + letter for letter in alphabet]\n        # `pmap` here does the requests to Discovery concurrently to save time.\n        results = pmap(maybe_some_ids, prefixes)\n        for result in results:\n            if isinstance(result, list):\n                doc_ids += result\n            else:\n                prefixes_to_process.append(result)\n\n    return doc_ids\n############################################"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "############################################\n# Watson Assistant backup\n############################################\nif(wa_version == '' or wa_apikey == '' or wa_url == ''):\n    print(\"No or invalid Watson Assistant credentials detected. Skipping.\")\nelse:\n    print(\"Starting Watson Assistant backup...\")\n\n    assistant_service=ibm_watson.AssistantV1(\n        version = wa_version,\n        iam_apikey = wa_apikey,\n        url = wa_url\n    )\n\n    # Get all workspace IDs\n    try:\n        list_wrkspc_response = assistant_service.list_workspaces().get_result()['workspaces']\n        all_wrkspc_ids = []\n    except ApiException as ex:\n        print(\"Method failed with status code \" + str(ex.code) + \": \" + ex.message)\n\n    print(\"Getting workspace IDs...\")\n    for space in list_wrkspc_response:\n        print(\"Backing up Workspace \"+ space['workspace_id'] + \"...\")\n        all_wrkspc_ids.append(space['workspace_id'])\n\n    for id in all_wrkspc_ids:\n        workspace_response = []\n\n        try:\n            workspace_response = assistant_service.get_workspace(\n                workspace_id = id,\n                export='true'\n            ).get_result()\n        except ApiException as ex:\n            print(\"Method failed with status code \" + str(ex.code) + \": \" + ex.message)\n            \n        intents = workspace_response['intents']\n        intentsCSV = ''\n        for intent in intents:\n            intent_name = intent['intent']\n            for example in intent['examples']:\n                intentsCSV += example['text'] + ',' + intent_name + '\\n'\n\n        entities = workspace_response['entities']\n        entitiesCSV = ''\n        for entity in entities:\n            entity_name = entity['entity']\n            for value in entity['values']:\n                entitiesCSV += entity_name + ','\n                entitiesCSV += value['value'] + ','\n                if value['type'] == 'synonyms':\n                    if len(value['synonyms']) > 0:\n                        for synonym in value['synonyms']:\n                            entitiesCSV += synonym + ','\n                if value['type'] == 'patterns':\n                    entitiesCSV += '/' + value['patterns'][0] + '/'\n                entitiesCSV = entitiesCSV.rstrip(',')\n                entitiesCSV += '\\n'\n        \n        project.save_data(\"wa_\" + id + \"_workspace.json\", json.dumps(workspace_response), set_project_asset=True, overwrite=True)\n        project.save_data(\"wa_\" + id + \"_intents.csv\", intentsCSV, set_project_asset=True, overwrite=True)\n        project.save_data(\"wa_\" + id + \"_entities.csv\", entitiesCSV, set_project_asset=True, overwrite=True)\n\n        print(\"Workspace \" + id + \" done.\")\n    print(\"Completed Watson Assistant backup.\")\n######## End Watson Assistant Backup ########"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "############################################\n# Discovery Backup\n############################################\n# This script will loop through every collection in the given instance and save each document. If you only want a specific collection to be backed up, remove the outer loop.\n\nif(disc_version == '' or disc_apikey == '' or disc_url == ''):\n    print(\"No or invalid Discovery credentials detected. Skipping.\")\nelse:\n    print(\"Beginning Discovery backup...\")\n\n    discovery_service = ibm_watson.DiscoveryV1(\n        version=disc_version,\n        iam_apikey=disc_apikey,\n        url=disc_url\n    )\n\n    environments = discovery_service.list_environments().get_result()\n    environmentId = environments[\"environments\"][1][\"environment_id\"]\n    allCollections = discovery_service.list_collections(environmentId).get_result()['collections']\n\n    for collection in allCollections:\n        collectionId = collection['collection_id']\n        print(\"Backing up collection \" + collectionId + \"...\")\n        allDocIds = all_document_ids(discovery_service, environmentId, collectionId)\n\n        try:\n            training_data = discovery_service.list_training_data(environmentId, collectionId).get_result()\n        except ApiException as ex:\n            print(\"Discovery query failed with status code \" + str(ex.code) + \": \" + ex.message)\n            \n        project.save_data(\"wds_\" + collectionId + \"_trainingdata.json\", json.dumps(training_data), set_project_asset=True, overwrite=True)\n\n        for documentId in allDocIds:\n            filterId = '_id:' + documentId\n            try:\n                discQuery = discovery_service.query(environmentId, collectionId, filter=filterId).get_result()['results'][0]\n            except ApiException as ex:\n                print(\"Discovery query failed with status code \" + str(ex.code) + \": \" + ex.message)\n                \n            project.save_data(\"wds_document_\" + documentId + \".json\", json.dumps(discQuery), set_project_asset=True, overwrite=True)\n\n        print(\"Collection \" + collectionId + \" successfully backed up.\")\n\n    print(\"Completed Discovery backup.\")\n\n######## End Discovery Backup ########"
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}